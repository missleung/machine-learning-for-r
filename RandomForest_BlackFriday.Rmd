---
title: "Random Forest"
author: "Lisa Leung"
date: '2019-01-27'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load all libraries

```{r}
library(tidyverse)
library(caret)
library(randomForest)
library(quantregForest)
```
## Purpose

We will conduct random forest to predict the number of purchase made

```{r}
# Loading data
dat_User <- read_csv("BlackFriday-User.csv")
dat_User <- dat_User[,!colnames(dat_User) %in% c("X1", "User_ID")]


# Train and Test data
set.seed(10)
num <- round(nrow(dat_User)/2)
vec_Train <- sample(1:nrow(dat_User),size = num)

dat_Train <- dat_User[vec_Train,]
dat_Test <- dat_User[-vec_Train,]
```

## Let's start the random forest!

```{r}
seed <- 10
set.seed(seed)

# Setting parameters on mtry tuning
control <- trainControl(method="repeatedcv", number=10, repeats=3) # using 10-fold, repeating 3 times from caret
metric <- "RMSE" #A string that specifies what summary metric will be used to select the optimal model. By default, possible values are "RMSE" and "Rsquared" for regression and "Accuracy" and "Kappa" for classification. 
mtry <- sqrt(ncol(dat_Train))
tunegrid <- expand.grid(.mtry=mtry) # Looking at the randomly selected predictors

# Running the random forest
rf_default <- train(sum_Purchase~Gender+Age+Occupation+City_Category+Stay_In_Current_City_Years + Marital_Status, data=dat_Train, method = 'qrf', metric=metric, tuneGrid=tunegrid, trControl=control) #using quantile random forest to train. Tuning parameters uses mytry (randomly selected predictors)
print(rf_default)
```

